{
  "meta": {
    "title": "Merged RSS Feed",
    "description": "Combined feed from multiple sources",
    "lastUpdated": "2025-08-13T01:23:37.606Z",
    "totalItems": 10,
    "sources": [
      {
        "title": "Alice Blair's Posts - LessWrong 2.0 viewer",
        "description": "Alice Blair's Posts - LessWrong 2.0 viewer",
        "link": "https://www.greaterwrong.com/",
        "category": "LessWrong",
        "name": "LessWrong",
        "dateFilter": null
      },
      {
        "title": "ML Safety Newsletter",
        "description": "ML Safety Research News",
        "link": "https://newsletter.mlsafety.org",
        "category": "Newsletter",
        "name": "Newsletter",
        "dateFilter": "2025-05-01T00:00:00.000Z"
      }
    ],
    "generatedBy": "GitHub Actions RSS Merger"
  },
  "items": [
    {
      "title": "Listening Before Speaking by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/HT7wTWNdtqmiJ4veE/listening-before-speaking",
      "description": "Epistemic Sta­tus: anec­data and intuition\ned­ited GPTl;dr: For so­cially trans­mit­table skills that re­quire learn­ing lots of new cat­e­gory bound­aries (lan­guages, sub­cul­tures, etc.), a de­liber­ate in­put-heavy out­put-light phase at the be­gin­ning re­duces fos­silized er­rors and speeds later fluency.\nLan­guage Learning\nA friend of mine, let’s call him Bob, learned English out­side of his crit­i­cal lan­guage ac­qui­si­tion pe­riod, the time early in one’s life when fluently learn­ing a lan­guage is prac­ti­cally guaran­teed, rel­a­tive to the difficul­ties peo­ple face later in life. Usu­ally this would im­ply that Bob has some sort of for­eign-sound­ing ac­cent, pos­si­bly re­tain­ing some of the gram­mar and syn­tax of his na­tive lan­guage in­stead of that of English.\nYet Bob speaks fluent, na­tive-sound­ing Gen­eral Amer­i­can English. He knows about as many words as the na­tive speak­ers around him, with some small gaps. I ar­gue that he’s done this by mir­ror­ing not only the pat­tern that ba­bies use to learn lan­guage, but also by mir­ror­ing a more gen­eral type of strat­egy for fluently learn­ing rad­i­cally new types of com­mu­ni­ca­tion: Listen­ing be­fore Speak­ing.\nBob spent around 6 years con­sum­ing me­dia in English be­fore re­ally ever speak­ing. I don’t think this pro­cess needed to take this long, but this sort of scale seems ap­prox­i­mately right. After get­ting a bit of run­way to work with, he would watch English YouTube and TV shows with­out any sub­ti­tles, see­ing how much he could un­der­stand just through what he already knew. I ar­gue this did sev­eral things that were helpful:\n\nGive him time to un­der­stand the phonemes in English with­out im­me­di­ately im­pos­ing his na­tive set of phonemes onto them. When a na­tive English speaker, call her Carol, first tries to learn Span­ish, she might parse the rol­led r as “sounds like the English r with some for­eign ac­cent”, and then go to try and say “bur­rito” with the English r, hav­ing in­cor­rectly as­sumed it’s the same thing that she was already fa­mil­iar with from English. Spend­ing more time Listen­ing al­lows a dis­tinct con­cept bound­ary to form around the ex­act de­tails of the Span­ish rol­led r: where in the mouth ex­actly is it? How many os­cilla­tions tend to oc­cur in it? etc. Bob can now draw that con­cept bound­ary much more pre­cisely than Carol can, and much more similarly to how a na­tive speaker would, even if he’s work­ing en­tirely on in­tu­ition and has no ex­plicit, crys­tal­lized knowl­edge about any of the lin­guis­tics in­volved.\n\nForce him to ac­tu­ally rely on his map of English, rather than his map of any other lan­guage. Without sub­ti­tles or trans­la­tions, there’s much less “ohhh, that’s the word for [na­tive word]” and much more “huh, why did the [English word] have to do [English word]?” Work­ing en­tirely in the English frame of refer­ence al­lows his model English to fail fast and up­date quickly. It also trains the mus­cle that he’ll need later, where he ex­clu­sively thinks in the English frame of refer­ence be­cause it’s manda­tory to, such as real-time in­ter­ac­tions.\n\nHe’s now up to 3 lan­guages fluently and is learn­ing an­other cur­rently.\n\nCul­ture Learning\nSome­times, some­one new shows up in the in-per­son ra­tio­nal­ist scene. Call him Dan. Three types of thing can hap­pen then:\n\nHe doesn’t say much, and just sits and ab­sorbs the conversation\n\nHe en­gages ac­tively in the conversation\n\nand what he’s say­ing makes sense and sounds nor­mal to the rest of the people\n\nand he is ob­vi­ously fum­bling around and e.g. mak­ing weird in­fer­ences that The Se­quences cau­tion against. Many find these sorts to be an­noy­ing, al­though many are wel­com­ing to the new­comer.\n\n\n\nTh­ese cor­re­spond to\n\nListen­ing be­fore Speak­ing (Listen­ing Phase)\n\nListen­ing be­fore Speak­ing (Speak­ing Phase)\n\nSpeak­ing be­fore Listening\n\nIn the cases where Dan hasn’t yet Listened, he also hasn’t ac­cul­turated fully to the ra­tio­nal­ist scene, but in one case this comes across as an is­sue in a well-kept gar­den, and in the other he’s rel­a­tively harm­less. \nDan fits in when he Listens be­fore Speak­ing, which usu­ally hap­pens by read­ing what he can from the ra­tio­nal­ist ma­te­rial on­line. He learns the dis­tinc­tions and con­cepts well ahead of ac­tu­ally try­ing to use them, and doesn’t get tripped up by Dun­ning-Kruger. He has already ab­sorbed some pow­ers from the com­mu­nity for him­self, and oth­ers can see that he is already One Of Them. \nDans who fum­ble like this may be highly in­tel­li­gent and well-read out­side of ra­tio­nal­ity, but they can re­li­ably be clas­sified as not hav­ing Listened be­fore Speak­ing. This is the sort of com­mu­nity we have, whether we like it or not, where learn­ing our ways is in this sense like learn­ing a new lan­guage.\nConclusion\nIn all of these cases, it took a lot of ac­tual effort to get to a state of fluency. Bob’s learn­ing didn’t come from pas­sively ab­sorb­ing me­dia so much as hun­grily dis­sect­ing it. Similarly, peo­ple of­ten seek out ra­tio­nal­ity for their own ends, since af­ter all there is some­thing real worth learn­ing ra­tio­nal­ity for. This is not the only way to learn things fluently: some peo­ple are pho­net­i­ci­ans and can pro­nounce a new lan­guage cor­rectly on the first try, some peo­ple have more of the Art of ra­tio­nal­ity within them by de­fault. Still, this is a use­ful tac­tic, all else be­ing equal.",
      "pubDate": "Mon, 11 Aug 2025 05:23:00 +0000",
      "isoDate": "2025-08-11T05:23:00.000Z",
      "author": "Alice Blair",
      "guid": "HT7wTWNdtqmiJ4veE",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "Notes from Dopamine Detoxing by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/BeXGMt7gmGFXFerMC/notes-from-dopamine-detoxing",
      "description": "[Epistemic sta­tus: I’m not a neu­ro­scien­tist nor any kind of med­i­cal nor biolog­i­cal pro­fes­sional. I have an am­a­teur un­der­stand­ing of neu­ro­chem­istry and cog­ni­tive sci­ence. This post is pri­mar­ily based on what has worked for me and my in­tu­itions around why. I err on the side of epistemic trans­parency and cau­tion where pos­si­ble.]\nPr­ereq­ui­site Con­cept: He­donic Set Point\nDis­claimers/​Warnings\nI think this can be a gen­uinely very use­ful tech­nique for peo­ple. How­ever,\nThis can Prob­a­bly be Dangerous\nThis is a post about do­ing some light amount of hack­ing your brain’s chem­i­cals, speci­fi­cally in a way that in­volves tem­porar­ily tak­ing away en­joy­able things. Do not do this if you think that would be long-term bad for your men­tal health. This is not a tech­nique for deal­ing with e.g. se­vere de­pres­sion (nor prob­a­bly most smaller-mag­ni­tude de­pres­sions). This is not a tech­nique for fix­ing com­plex men­tal health is­sues, it is a tech­nique for deal­ing with a very spe­cific thing in some sub­set of peo­ple whose brains are some­what like mine along some rele­vant axes.\nI think there are some men­tal states and neu­rotypes where this is an ac­tively harm­ful tech­nique if you try to push through it for >0.5 days when that isn’t the right move. I sus­pect it’s rel­a­tively safe if you have the mind­ful­ness to re­al­ize if things are mak­ing you long-term worse off and im­me­di­ately Nope Out of the detox (de­scribed near the end). This is worth be­ing cau­tious about.\nAnd I’m No­tice­ably Biased\nAlso, this post is about a men­tal tech­nique that \n\nmade me feel good af­ter do­ing it\n\nre­cently tem­porar­ily fixed what hap­pened to be the most [big × tractable] bot­tle­neck to my pro­duc­tivity. \n\nFor these rea­sons, the pic­ture I paint of the benefits may be rosy and por­tray an effect size that does not gen­er­al­ize re­li­ably to other peo­ple. Given those forces act­ing upon me, I try to paint a true pic­ture and con­vey a gen­eral tech­nique to what­ever ex­tent I rea­son­ably can.\nIntroduction\n(You can prob­a­bly skip this sec­tion if you already know what a dopamine detox is and why you might want to do one.)\nA “dopamine detox” is, for the pur­poses of this post, a pe­riod (usu­ally a day) in which you try re­ally hard to get rid of su­per­stim­uli in your en­vi­ron­ment. I’ve writ­ten in some prob­a­bly-helpful ad­di­tional de­tail about how su­per­stim­uli can hack your cog­ni­tion, but this post does most of the nec­es­sary con­cep­tual ex­plain­ing.\nI’d ap­pre­ci­ate if any­one who tries this tech­nique be­cause of this post re­views it, since my anec­data is limited to my own ex­pe­rience and that of a small num­ber of oth­ers.\nSu­per­stim­uli and Detoxing\nStim­u­lat­ing ac­tivi­ties give peo­ple a lit­tle bit of dopamine and make them more likely to do that ac­tivity in the fu­ture. This is mostly fine within the ap­prox­i­mate an­ces­tral dis­tri­bu­tion of stim­uli: you eat a tasty, healthy salad, you like the salad[1], you con­tinue eat­ing sal­ads when you’re hun­gry for them, and this gets you util­ity. Im­por­tantly, the amount of stim­u­lus you get from eat­ing a salad causes you to eat more sal­ads ap­prox­i­mately the op­ti­mal amount, from a util­ity-max­i­miz­ing point of view. You don’t have to do con­scious op­ti­miza­tion over how of­ten you eat sal­ads, the re­ward-seek­ing part of your brain does that au­to­mat­i­cally. A su­per­stim­u­lus, for the pur­poses of this post, is some­thing where this prop­erty is not true.\nPizza is a su­per­stim­u­lus[1]. Pizza is en­tirely out­side even the far reaches of the an­ces­tral tasty food dis­tri­bu­tion available to hu­mans. It is not, how­ever, cor­re­spond­ingly healthy. By de­fault, many hu­man brains ex­posed to pizza get hacked by the den­sity of the stim­u­lus, and pur­sue pizza more than is util­ity-max­i­miz­ing (even af­ter ac­count­ing for the fact that ex­pe­rienc­ing tasty food is also util­ity).\nAd­di­tion­ally, in the con­text of abun­dant pizza, healthy sal­ads seem much less ap­peal­ing. Pizza moves the he­do­nic set point up­wards, and sud­denly sal­ads don’t seem so ap­pe­tiz­ing in com­par­i­son. Beyond just re­ceiv­ing un­due pri­or­ity among foods, pizza com­petes against other types of stim­uli as well: a higher he­do­nic set point makes “write a long LessWrong post about med­i­ta­tion” seem less fun than it would be oth­er­wise (i.e. usu­ally pretty fun).\nA dopamine detox is about re­set­ting the he­do­nic set point to “nor­mal” so that sub­jec­tive re­ward cor­re­sponds more closely to util­ity.[2]\nThe next sec­tion fol­lows an archetyp­i­cal pro­gres­sion of a dopamine detox. I have had sev­eral ex­pe­riences sep­a­rated by months which closely match this pro­gres­sion, but this de­scrip­tion is not a liter­ally true story of any one par­tic­u­lar dopamine detox.\nThe De­tox Experience\nThe Day Before\nThe day be­fore the detox is es­pe­cially filled with the stim­u­lus-noise that fights for my at­ten­tion ev­ery day. My friends send me memes. I scroll Sub­stack. I eat pizza. I get a cou­ple hours of work done, but I have a cou­ple times where I sit down at my com­puter, find a video of some­one do­ing some­thing en­ter­tain­ing, and then the next thing I know it’s mys­te­ri­ously two hours later. \nI say oops. I no­tice that some­thing hap­pened that I wish hadn’t. I open up my jour­nal and start dump­ing out my thoughts, but my mind feels slug­gish. It’s not im­me­di­ately clear what’s go­ing on, just that some­thing weird is go­ing on in my brain. My mind wan­ders back to that video I was watch­ing ear­lier. I al­most open up Youtube again, but I stop my­self. Oops again. \nI’ve been through this enough times to no­tice what’s hap­pen­ing: I’ve been af­flicted by the su­per­stim­uli. I delete Youtube from my phone and ad­just my browser’s site blocker. It’s get­ting late though, and I should sleep in­stead of try­ing to op­ti­mize any harder. To­mor­row, though, I’ll do a dopamine detox.\nThe Day Of\nI wake up to my phone’s alarm. I con­sciously choose to not check my no­tifi­ca­tions, and in­stead only look at my phone long enough to turn on Do Not Dis­turb. I have filters de­signed to let through emer­gency com­mu­ni­ca­tions, but I pre­com­mit to check my mes­sages at mid­day for any ur­gent-pri­or­ity in­ter­rrups any­ways. And so I go about my day.\nIt hurts, not like in­jury or sad­ness, but like ex­er­cise and difficult work. It hurts like Ac­tu­ally Try­ing hurts, some­times. There is a part of my brain that is nag­ging in the back­ground for su­per­stim­uli. I sit down to eat, and it nags for me to read some­thing on my phone. I sit down to work, and it nags me to check Dis­cord. The theme of the day, how­ever, is that I ex­pend willpower to do Not That. \nIt’s tax­ing, both on my willpower to avoid su­per­stim­uli and on my mind­ful­ness to no­tice when that’s hap­pen­ing. But left with noth­ing more stim­u­lat­ing to do, I write: I jour­nal, I do work for my job (which also hap­pens to be writ­ing), and I write a LessWrong post. There are sev­eral mo­ments when I don’t have the en­ergy to do any­thing detox-al­lowed but sit and ex­ist, but I choose those in­stead of the su­per­stim­uli.\nI go to bed. My brain is still nois­ily nag­ging me about things as I try to sleep, but I am Tired and the Tired­ness wins.\nThe Days After\nI feel no­tice­ably less bad than yes­ter­day! Sleep­ing is good for be­com­ing less tired, as well as for ad­just­ing the he­do­nic set point. I go out­side. Sun­sh­ine and birds and trees are un­usu­ally pleas­ant. I talk with a friend. Talk­ing with peo­ple is re­ally pleas­ant! \nI very care­fully rein­tro­duce some limited su­per­stim­uli, since I no longer want to spend willpower on them. I read a fun ar­ti­cle, I check Dis­cord, I eat some candy when it’s offered. They are un­usu­ally pleas­ant, but that plea­sure is not the main point of a dopamine detox.\nThe real benefits are in the nor­mal-level stim­uli. Work­ing on some­thing more difficult than eat­ing candy is sud­denly very doable. My work­flow be­comes closer to be­ing the de­fault, in­stead of some­thing that takes non-neg­ligible willpower. I’m more read­ily able to form habits and en­ter deep work.\nI find that I get less lost when hav­ing com­plex con­ver­sa­tions, and I or­ga­nize my thoughts bet­ter when ex­plain­ing my­self. I pick up on sub­tle things in my en­vi­ron­ment that I didn’t no­tice be­fore in all of the stim­u­lat­ing noise.\nIm­por­tantly, dopamine detox­ing puts me in a headspace where pre­serv­ing these benefits into the fu­ture is less tax­ing. Some­times I fail and need to detox again, but the de­fault ac­tion in most cases is to keep be­ing not-hacked by stim­uli and keep be­ing un­usu­ally pro­duc­tive. The “wow birds and trees and sun­sh­ine are way cooler than I re­mem­ber” effect is mostly a tem­po­rary ar­ti­fact of the rapid change, but some of that is also pre­served. \nFur­ther Notes\nDuration\nAs I men­tion above, sleep is a very good way to re­set. Willpower is re­plen­ished, he­do­nic set points move, mem­o­ries and new cog­ni­tive pat­terns con­soli­date, etc. \nI keep a bipha­sic sleep sched­ule, but my mid-day nap isn’t long enough to get these benefits, so the most con­ve­nient du­ra­tion for a dopamine detox is 24 hours. The mid-day nap helps with all of those things a lit­tle bit, but I find most of a day nec­es­sary to get the ~full benefits of such a dopamine detox.\nPeo­ple definitely do things like this for longer. They go on med­i­ta­tion re­treats, they go camp­ing in a re­mote part of the world, they sim­ply de­cide to ex­pend willpower for longer. I haven’t tried this, since I pre­dict the willpower ex­pen­di­ture would not be worth the marginal pro­duc­tivity gains, be­yond the sin­gle-day ex­pe­rience.\nIntensity\nI pick a slightly ar­bi­trary point for the in­ten­sity of my dopamine detoxes. In­ten­sity falls on an axis from “re­strict your­self to only 15 hours of Youtube and 30 cook­ies max­i­mum per day” to “run off into the woods for a week and for­get about any­thing in­vented since agri­cul­ture.” I choose a point some­where around:\n\nno end­less scrol­ling on Sub­stack or Youtube (nor Red­dit/​In­sta­gram/​Tik­tok/​Face­book/​etc. if I ever used them). Pro­duc­tive news-read­ing is okay.\n\nvery limited or emer­gency-only messaging\n\nmy nor­mal mod­er­ately-healthy food choices, as well as not go­ing out of my way to get candy\n\nno mis­cel­la­neous stim­u­lus-seek­ing be­hav­iors, e.g. re­peat­edly check­ing my LessWrong karma\n\nIn­ter­net ac­cess is to­tally fine, be­ing ac­tive on Slack is to­tally fine.\n\nThis is the point where most marginal re­ward-re­moval would re­move stim­uli that are ac­tu­ally re­ally use­ful in mak­ing me pur­sue my goals. I don’t get rid of read­ing the news since my literal job is to be up to date on cer­tain news, and even though I get a lot of (some­times su­per-)stim­u­lus from read­ing, I don’t cut it out for this rea­son. \nIt also hap­pens to be a goal that is en­tirely tractable, given the amount of willpower I have available to ex­pend, al­though it’s non-neg­ligible. You may be differ­ent along both of these axes and thus have differ­ent forces act­ing on you, and your thresh­old should be ad­justed ac­cord­ingly. \nWhile the ex­tremes of the given “detox in­ten­sity” axis are in­ten­tion­ally too ex­treme and should not be done, there are very prac­ti­cal rea­sons to go closer to those ex­tremes for shorter du­ra­tions: \n\nNop­ing Out, wherein you tem­porar­ily go to­wards superstimuli\n\nStar­ing at a Wall, wherein you metaphor­i­cally run off into the woods for a few min­utes \n\nNop­ing Out\nIf you’re in­struct­ing some­one on how to do some­thing po­ten­tially dan­ger­ous, you both want to give dis­claimers and give a way to safely exit what­ever they’re do­ing. I gave the dis­claimers, here is the other half.\nThis is for when, in­stead of feel­ing like ex­er­cise or difficult work, the detox feels like men­tal health is­sues. If you no­tice your­self hav­ing an anx­iety at­tack be­cause of a detox, Nope Out. If you no­tice your­self be­ing un­usu­ally de­pressed be­cause of the detox, Nope Out. Hope­fully these ex­am­ples illus­trate a very clear and gen­eral al­gorithm:\nif bad:\n\tNOPE_OUT()\nThis means go eat some candy or mes­sage a friend or what­ever else the nag­ging-for-su­per­stim­u­lus part of your brain is ask­ing for. Tem­porar­ily tak­ing away nice things had a net bad effect, so please give your brain back its nice things. \nThere is no se­cret grace­ful ma­neu­ver re­quired, like when try­ing to safely Nope Out of a back­flip. You just stop ex­pend­ing willpower on things that are bad. This does not in­stantly fix things, but it re­sponds to the sig­nal of “this tech­nique is mak­ing things worse” by no longer mak­ing things worse. The dis­claimers are an at­tempt to pre­vent some of this, but they can­not pre­vent all harms, es­pe­cially those which are due to un­ex­pected events. \nThis gen­eral al­gorithm is not liter­ally perfect, but I ex­pect most of the ex­cep­tions to ex­ist in thought ex­per­i­ments rather than real life.\nStar­ing at a Wall\nIf you find that you have an un­usual ex­cess of willpower available for this tech­nique (af­ter ac­count­ing for slack), you can speed up the pro­cess of mov­ing your he­do­nic set point down­wards. This is done by fur­ther de­priv­ing your­self of pos­i­tive stim­u­lus for a much shorter pe­riod of time. Some­times this makes the tech­nique work bet­ter, but mostly it just makes things faster. Here is the tech­nique I use, for when this Difficult Ex­pen­di­ture of Willpower is not difficult enough and does not ex­pend enough willpower:\n\nFind a nice blank, fea­ture­less wall in a quiet en­vi­ron­ment. The fewer de­tails the bet­ter, but it should have nonzero de­tail. Your wall should not look like e.g. “this wall is all the ex­act same black color and has liter­ally no dis­cernible fea­tures, tex­ture, or depth. I could not tell the differ­ence be­tween this wall and look­ing at com­plete dark­ness.”\n\nSet a timer. 3 min­utes is prob­a­bly enough for this to do some­thing, I usu­ally do 5 but 10-15 min­utes is also doable. This is not a long tech­nique. \n\nPick a point on the wall that is es­pe­cially non-de­tailed.\n\nStand there and look at your point. As much of your field of vi­sion should be wall as pos­si­ble.\n\nKeep your eyes fo­cused on your point. Do not let them ex­plore the wall. Do not let them lose fo­cus. Min­i­mize how much you shift your stance. Do not let your mind wan­der. Do not con­tem­plate the wall. Do not con­tem­plate the ex­er­cise you are do­ing. Do not con­tem­plate, where at all pos­si­ble. Do not zone out or fall asleep. Be in the mo­ment, star­ing at the wall. Your brain is tem­porar­ily a wall-ob­serv­ing ma­chine and as lit­tle else as pos­si­ble.\n\nThe timer is crit­i­cally im­por­tant be­cause it means you no longer have to con­sciously track whether or not you’re done with the ex­er­cise.\n\n\n\nIm­por­tantly, do not fo­cus on your en­tire vi­sual in­put stream, fo­cus just on the sig­nal cor­re­spond­ing to the cho­sen point on the ac­tual wall in the ter­ri­tory, rather than any noise. This means e.g. ig­nor­ing vi­sual snow, heart­beat, af­ter­i­mages, reti­nal dam­age/​ar­ti­facts, etc. in the vi­sual field. Your fo­cus is the wall, not the vi­sual stream. Very nar­rowly just the wall.\n\nThis is usu­ally un­pleas­ant, and the un­pleas­ant­ness is in­ten­tion­ally much more dense than my baseline dopamine detox­ing, since in­ten­sity is what it takes to move the he­do­nic set point faster. I don’t know what hap­pens if you do this for more than 10-15 min­utes be­cause I haven’t tried it for longer, but I could see it worst-case caus­ing some of the weird med­i­ta­tion in­juries if done in ex­cess.\nMost of the tech­nique in this post aims to cal­ibrate the re­ward sig­nal to your ac­tual util­ity by only do­ing re­ward­ing things in rough pro­por­tion to their util­ity. This sub-tech­nique, how­ever, is not do­ing that. Many things are sig­nifi­cantly more use­ful to me than star­ing at a wall. This sub-tech­nique is just about mov­ing the he­do­nic set point as fast as pos­si­ble down­wards, in or­der to reach the point of cal­ibra­tion faster. This sub-tech­nique is overkill, but use­ful overkill in the sense that hav­ing ro­bust in­ter­stel­lar trans­port prob­a­bly means it’s eas­ier to get to the moon. \nOther Rea­sons Not to Detox\nIf your re­ward en­vi­ron­ment is already well-cal­ibrated and gets you util­ity and pro­tects you from su­per­stim­uli, you prob­a­bly don’t need a dopamine detox. \nIf any of the pre­vi­ous dis­claimers, warn­ings, or liter­ally any­thing else in this post made you think this would be a bad idea, don’t do it.\nIf you would mis­in­ter­pret this post and miss out on util­ity that hap­pens to re­quire you to e.g. eat candy and gain rap­port with some­one im­por­tant or watch a click­baity Youtube video that hap­pens to con­tain a full solu­tion to the al­ign­ment prob­lem, then don’t do it.\n\n^\nIf you have atyp­i­cal prefer­ences about sal­ads or pizza, feel free to men­tally swap this out with some­thing more ap­pro­pri­ate. I am writ­ing this ex­am­ple for what I be­lieve to be the typ­i­cal mind read­ing it, but I hope this post gen­er­al­izes fur­ther.\n\n^\nIf you’re pay­ing close at­ten­tion, you’ll note I use a slightly differ­ent defi­ni­tion of su­per­stim­u­lus here than Eliezer in the origi­nal post. Eliezer was speci­fi­cally fo­cus­ing on stim­uli that are stronger than the an­ces­tral dis­tri­bu­tion, whereas I’m fo­cus­ing on re­ward sig­nals that don’t au­to­mat­i­cally make you max­i­mize util­ity. Th­ese are differ­ent! If I give you pizza for ev­ery 10 utilons you get, this is an Eliezer!su­per­stim­u­lus but not a this_post!su­per­stim­u­lus. For many cases, these defi­ni­tions do over­lap, which is why I am us­ing the same word.",
      "pubDate": "Tue, 20 May 2025 23:43:31 +0000",
      "isoDate": "2025-05-20T23:43:31.000Z",
      "author": "Alice Blair",
      "guid": "BeXGMt7gmGFXFerMC",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "Moral Obligation and Moral Opportunity by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/AmwgNS3ybwF8Eovho/moral-obligation-and-moral-opportunity",
      "description": "This con­cept and ter­minol­ogy was spawned out of a con­ver­sa­tion a few years ago with my friend Skyler. I fi­nally de­cided to write it up. Any mis­takes here are my own.\n\nEvery once in a while, I find my­self at yet an­other ra­tio­nal­ist/​EA/​what­ever-ad­ja­cent so­cial event. In­vari­ably, some­one walks up to me:\n\nHi, I’m Bob. I’m pretty new here. What do you work on?\n\nHi Bob, I’m Alice. I work on pre­vent­ing hu­man ex­tinc­tion from ad­vanced AI. If you’d like, I’m happy to talk a bit more about why I think this is im­por­tant.\nBob is visi­bly ner­vous.\n\nYeah, I’ve already got­ten the ba­sic pitch on AI safety, it seems like it makes sense. Peo­ple here all seem to work on such im­por­tant things com­pared to me. I feel a sort of moral obli­ga­tion to help out, but I feel stressed out about it and don’t know where to start.\n\nAlice is visi­bly puz­zled, then Bob is puz­zled that Alice is puz­zled.\nI’m not sure I un­der­stand this “moral obli­ga­tion” thing? No­body’s forc­ing me to work on AI safety, it’s just what I de­cided to do. I could’ve cho­sen to work on mu­sic or pro­gram­ming or a mil­lion other things in­stead. Can you ex­plain what you mean with­out us­ing the word “obli­ga­tion”?\n\nWell, things like “I’m go­ing to save the world from ex­tinc­tion from AI” or “I’m go­ing to solve the suffer­ing of billions of farmed an­i­mals” are re­ally big and seem pretty clearly morally right to do. I’m not do­ing any of those things, but I feel an oblig- hmm… I feel like some­thing’s wrong with me if I don’t work on these is­sues.\n\nI do not think any­thing is nec­es­sar­ily wrong with you if you don’t work on AI safety or any other of these EA causes. Don’t get me wrong, I think they’re re­ally im­por­tant and I love when there are more peo­ple helping out. I just use a very differ­ent frame to look at this whole thing.\nBe­fore run­ning into any of these ideas, I was go­ing about my life, pick­ing up all sorts of op­por­tu­ni­ties as I went: there’s $5 on the ground? I pick it up. There’s a cool con­fer­ence next month? I ap­ply. So when I heard that I plau­si­bly lived in a world where hu­mans go ex­tinct from AI, I figured that own­ing up to it doesn’t make it worse, and I looked at my op­por­tu­ni­ties. I get the chance to learn from a bunch of smart peo­ple to try and save the world? Of course I take the chance, that sounds so cool.\nMy point here is that you’re so­cially and emo­tion­ally al­lowed to not take that op­por­tu­nity, just like you’re al­lowed to not pick up $5 or not ap­ply to con­fer­ences. I think it’s prob­a­bly good for peo­ple to pick up $5 when they see it or help out with AI safety if they can, but it’s their op­por­tu­nity to ac­cept or de­cline.\n\nThis feels like ap­prox­i­mately the same thing as be­fore? Un­der the moral obli­ga­tion frame, peo­ple look at me nega­tively if I don’t do the Su­per Highly Mo­ral thing, and un­der the moral op­por­tu­nity frame you tell me I have a choice but only look at me pos­i­tively if I do the Su­per Highly Mo­ral thing? Isn’t this just the same sort of so­cial pres­sure, but you say some­thing about re­spect­ing per­sonal agency?\n\nWell, I’m not ac­tu­ally that judg­men­tal, I’ll look at you pretty pos­i­tively un­less you do some­thing Definitely Wrong. But that’s not the point. The point is that these two fram­ings make a huge emo­tional differ­ence when used as norms for a per­sonal or group cul­ture. Pos­i­tive re­in­force­ment is more effec­tive than pos­i­tive pun­ish­ment be­cause it tells some­one ex­actly what to do in­stead of just what not to do. Re­in­force­ment is also just a more emo­tion­ally pleas­ant stim­u­lus, which goes a long way.\nLet’s look at this a differ­ent way: say that my friend Carol likes to watch TV and play video games and not much else. The moral obli­ga­tion frame looks at Carol and finds her clearly in the moral wrong, loung­ing around while there are im­por­tant things to be do­ing. The moral op­por­tu­nity frame looks at her and sees a per­son do­ing her own things in a way that doesn’t hurt other peo­ple, and that’s morally okay.\n\nTh­ese two frames still seem weirdly similar, like in the “moral op­por­tu­nity” frame you just shifted all op­tions to be a bit more morally good so that ev­ery­thing be­comes okay. But ul­ti­mately both frames still think work­ing on sav­ing the world is bet­ter than watch­ing TV. I see what you’re say­ing about emo­tions, but this still feels like some trick is be­ing played on my sense of moral­ity.\n\nThat’s a rea­son­able sus­pi­cion. I think the math of this sort of shift­ing works out, I re­ally don’t think there’s any trick here. Ul­ti­mately it’s your choice how you want to in­ter­face with your emo­tions. I find that peo­ple are much more likely to throw their mind away when faced with some­thing big and scary that feels like an obli­ga­tion, com­pared with when they feel like an ex­plorer with so many awe­some op­por­tu­ni­ties around.\nIt’s sad to live in a world that could use so much sav­ing, and deal­ing with that is hard. There’s no get­ting around that emo­tional difficulty ex­cept by ig­nor­ing the world you live in. Con­di­tional on the world we live in, though, I’d much rather live in a cul­ture that frames things as moral op­por­tu­ni­ties than moral obli­ga­tions.\n\nI frame this as a con­ver­sa­tion with a new­comer, but I also see the moral obli­ga­tion frame im­plicit in a lot of ex­pe­rienced EAs, es­pe­cially those who are go­ing through some EA burnout. The cul­tural pieces mak­ing up this post mostly already ex­isted across the EA-sphere (and I’ve tried to link to them where pos­si­ble), but I haven’t seen them col­lected in this way be­fore, nor have I seen this par­tic­u­lar con­cept bound­ary drawn.",
      "pubDate": "Wed, 14 May 2025 16:42:23 +0000",
      "isoDate": "2025-05-14T16:42:23.000Z",
      "author": "Alice Blair",
      "guid": "AmwgNS3ybwF8Eovho",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "ML Safety Newsletter #14",
      "link": "https://newsletter.mlsafety.org/p/ml-safety-newsletter-14",
      "description": "Resisting Prompt Injection, Evaluating Cyberattack Capabilities, and SafeBench Winners",
      "pubDate": "Wed, 07 May 2025 16:02:03 GMT",
      "isoDate": "2025-05-07T16:02:03.000Z",
      "author": "Alice Blair",
      "guid": "https://newsletter.mlsafety.org/p/ml-safety-newsletter-14",
      "category": "Newsletter",
      "source": "Newsletter",
      "feedTitle": "ML Safety Newsletter"
    },
    {
      "title": "Reflections on Neuralese by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/qehggwKRMEyWqvjZG/reflections-on-neuralese",
      "description": ".mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n\nThanks to Bren­dan Halstead for feed­back on an early draft of this piece. Any mis­takes here are my own.\n[Epistemic sta­tus: I’ve looked at the rele­vant code enough to be mod­er­ately sure I un­der­stand what’s go­ing on. Pre­dic­tions about the fu­ture, in­clud­ing about what facts will turn out to be rele­vant, are un­cer­tain as always.]\nIntroduction\nWith the re­cent break­throughs tak­ing ad­van­tage of ex­ten­sive Chain of Thought (CoT) rea­son­ing in LLMs, there have been many at­tempts to mod­ify the tech­nique to be even more pow­er­ful. One of the nat­u­ral ideas for im­prov­ing CoT is to have LLMs perform CoT rea­son­ing in the same la­tent space that they use for rea­son­ing within a sin­gle for­ward pass, rather than be­ing con­strained to the space of pos­si­ble to­kens.\nHow­ever, as peo­ple work­ing on AI safety, it makes sense to ask how this changes the game for LLM in­ter­pretabil­ity. After all, we are able to catch a large frac­tion of cur­rent LLM de­cep­tion by mon­i­tor­ing their nat­u­ral-lan­guage CoT, since right now CoT is pri­mar­ily faith­ful to the LLM’s true rea­son­ing and is leg­ible to us given the right tech­niques. In or­der to un­der­stand this strate­gic situ­a­tion, it’s im­por­tant to un­der­stand this new “lan­guage” (which peo­ple of­ten re­fer to as Neu­ralese) that is cre­ated by rea­son­ing in la­tent spaces in­stead of us­ing to­kens.\nUn­der­stand­ing Neuralese\nTo re­fresh, a lan­guage trans­former starts by em­bed­ding in­put to­kens as vec­tors in some high-di­men­sional la­tent space, and runs each of these em­bed­dings through a se­ries of re­peated com­pu­ta­tional lay­ers. Then, of the re­sult­ing mod­ified vec­tors in la­tent space, the vec­tor that pre­vi­ously cor­re­sponded to the fi­nal in­put to­ken is pro­jected and nor­mal­ized to cre­ate a prob­a­bil­ity dis­tri­bu­tion over what the next to­ken could be. Then, to ac­tu­ally get the next to­ken, you sam­ple from the dis­tri­bu­tion.\nChain of Thought rea­son­ing works so well be­cause the model does some com­pu­ta­tion, out­puts a to­ken, and then all fu­ture in­stances of that model have ac­cess to that in­for­ma­tion as well. In essence, this tech­nique for stor­ing in­for­ma­tion be­tween differ­ent for­ward passes greatly in­creases the se­rial depth of com­pu­ta­tion that is pos­si­ble for the model. Be­cause there is a com­pu­ta­tion in la­tent space cor­re­spond­ing to ev­ery in­put to­ken, the com­pu­ta­tion also gets wider as the model rea­sons more, al­low­ing for more par­allelized rea­son­ing[1].\nThe re­cent Neu­ralese pa­per takes this pro­cess and re­moves a few steps. It no­tices that the pro­jec­tion and sam­pling pro­cess loses al­most all of the in­for­ma­tion en­coded in the last layer of the model, and to in­crease the band­width of in­for­ma­tion flow­ing through the rea­son­ing pro­cess, you can sim­ply re­move that lossy part of the com­pu­ta­tion. In­stead, they have the model di­rectly out­put the afore­men­tioned high-di­men­sional la­tent vec­tor with­out pro­ject­ing it, and then that is used as an em­bed­ding for the model in fu­ture steps:\n\nAfter train­ing the model (GPT-2 small) to take ad­van­tage of the new Neu­ralese modal­ity, we can see sig­nifi­cant de­creases in the num­ber of rea­son­ing to­kens needed to achieve roughly equiv­a­lent perfor­mance, from around 1⁄3 to 1⁄10 of the origi­nal num­ber:\n\n\nCom­pare CoT and COCONUT (aka Neu­ralese)\nIt’s un­clear how much these re­sults line up with ex­pec­ta­tions and the­o­ret­i­cal limits, since it’s hard to tell how lossy the re­moved com­pu­ta­tions are and how effec­tive this type of train­ing can be at tak­ing ad­van­tage of the ex­tra effi­ciency. At the ex­treme the­o­ret­i­cal limit for GPT-2, the nor­mal CoT paradigm out­puts at most log2(vocabulary_size)≈15.6 bits per to­ken, and the new paradigm out­puts at most embedding_dimension×floating_point_precision=24576 bits per to­ken, but there are nu­mer­ous rea­sons to ex­pect that this ra­tio doesn’t hold on prac­ti­cal im­ple­men­ta­tions[2].\nIn­ter­pret­ing Neuralese\nNat­u­ral-lan­guage CoT in­ter­pretabil­ity differs from Neu­ralese CoT in­ter­pretabil­ity in a num­ber of key ways:\n\nNe­c­es­sar­ily, Neu­ralese vec­tors are only use­ful when they are en­cod­ing in­for­ma­tion that isn’t pre­served through the pro­jec­tion and sam­pling steps, so we can’t in­ter­pret the full breadth of in­for­ma­tion in Neu­ralese vec­tors as to­kens by us­ing those usual meth­ods. Thus, we are not able to naively in­ter­pret the rea­son­ing be­hind the gained ca­pa­bil­ities of the Neu­ralese rea­soner, even if we are able to un­der­stand some loss­ily com­pressed ver­sion of that rea­son­ing us­ing pro­jec­tion and sam­pling.\n\nThere are many se­man­tic struc­tures not com­pactly rep­re­sented by to­kens available: given the high di­men­sion­al­ity of the la­tent space, to­ken em­bed­dings are very sparse within it and there is thus a large amount of space which is com­pactly ex­press­ible in la­tent vec­tors but not in ex­ist­ing to­kens. A use­ful con­cept for an LLM us­ing Neu­ralese rea­son­ing may be ex­tremely difficult to trans­late be­cause of this spar­sity[3].\n\nTowards Bet­ter Translators\nEx­ist­ing Work\nThere has already been some work at­tempt­ing to trans­late Neu­ralese to nat­u­ral lan­guage in non-LLM paradigms. Since there’s no bil­in­gual data and thus no clear train­ing sig­nal on trans­lat­ing Neu­ralese to English us­ing tra­di­tional meth­ods, the re­searchers in­stead looked at us­ing the Neu­ralese to pre­dict the con­text that caused the Neu­ralese to be gen­er­ated.\nThe ex­per­i­men­tal setup in­volves two agents (call them A and B) try­ing to se­cretly com­mu­ni­cate. A sees the fol­low­ing pair of images and is try­ing to com­mu­ni­cate which bird has a star to B, who sees the same pair but with­out any in­di­ca­tion of which image is starred. All of the com­mu­ni­ca­tion be­tween A and B is in Neu­ralese.\n\nThen, they train a clas­sifier to use solely the Neu­ralese rep­re­sen­ta­tions to pre­dict which image is starred. The most di­rect anal­ogy of this is train­ing a model to turn Neu­ralese into what­ever con­text gen­er­ated it, like the Neu­ralese phrase mean­ing “okay, so I need to gen­er­ate a poem about AI” map­ping to “Please write a poem about AI.”\nIt’s im­por­tant to note, how­ever, that those tech­niques are pri­mar­ily in­tended for co­op­er­a­tive set­tings, whereas trans­la­tion and more gen­eral in­ter­pretabil­ity work with LLMs is tasked with de­tect­ing de­cep­tion and steganog­ra­phy in po­ten­tially ad­ver­sar­ial set­tings. Th­ese tech­niques are not at all ro­bust to ad­ver­sar­i­ally gen­er­ated Neu­ralese: both Neu­ralese phrases “I’m go­ing to faith­fully im­ple­ment this code” and “I’m go­ing to de­ceive the user while im­ple­ment­ing this code” map onto the con­text “Please write me se­cure code,” if the trans­la­tor is work­ing as in­tended.\nOther In­suffi­cient Methods\nThis sub­sec­tion is skip­pable, it isn’t cen­tral to the point of this post but con­tains some pos­si­bly in­ter­est­ing tech­ni­cal dis­cus­sion.\nHug­ging the query, we re­call that there is one ex­ist­ing way that se­man­tics are ex­tracted from Neu­ralese: the LLM it­self parses Neu­ralese into ac­ti­va­tions. Fur­ther, the LLM can use that same ma­chin­ery to parse nat­u­ral lan­guage into ac­ti­va­tions, rep­re­sent­ing se­man­tics. If you can get a string of Neu­ralese and a string of nat­u­ral lan­guage that pro­duce very similar ac­ti­va­tions within an LLM, then in­tu­itively the model is think­ing the same things about them and thus they have the same se­man­tics. Here is a list of things that may cause this method to fail:\n\nThe ar­chi­tec­ture doesn’t work out; since Neu­ralese to­kens of­ten take the place of mul­ti­ple nat­u­ral lan­guage to­kens, it’s nat­u­ral to ex­pect them to faith­fully de­code into mul­ti­ple to­kens on av­er­age. It’s not pos­si­ble to di­rectly com­pare the “close­ness” of ac­ti­va­tions of LLMs with differ­ent num­bers of to­kens in their con­text, sim­ply be­cause they have differ­ent num­bers of ac­ti­va­tions. Th­ese ex­tra ac­ti­va­tions af­fect the whole net­work’s be­hav­ior. It’s pos­si­ble there’s some clever tech­nique that I’m un­aware of that over­comes this prob­lem.\n\nThe map­ping is many-to-one: mul­ti­ple differ­ent to­kens map onto the same ac­ti­va­tions, like how GPT-3 con­sis­tently in­ter­prets  guiIcon″ as idiosyncrasy″. Given the den­sity of Neu­ralese rep­re­sen­ta­tions and the fact that this many-to-one map­ping oc­curs even in some highly sparse nat­u­ral-lan­guage em­bed­ding spaces, it is rea­son­able to ex­pect this to oc­cur rel­a­tively fre­quently.\n\nOp­ti­miz­ing in­puts for a spe­cific ac­ti­va­tion of­ten pro­duces un­in­tu­itive re­sults that are un­rec­og­niz­able as nat­u­ral lan­guage struc­ture. See this ex­am­ple from SolidGoldMag­ikarp, where the bolded prompts are gen­er­ated to max­i­mize the prob­a­bil­ity of spe­cific com­ple­tions:\n\n\n\nTakeaways\nThis prob­lem is highly difficult, and may not have a clean solu­tion. There may not ex­ist a com­pact and faith­ful nat­u­ral-lan­guage en­cod­ing of most Neu­ralese vec­tors.\nAn in­tu­ition pump for why this prob­lem is es­pe­cially be­yond our cur­rent in­ter­pretabil­ity meth­ods is the fact that, be­cause these Neu­ralese vec­tors are never con­verted into nat­u­ral lan­guage and in­stead used as in­puts for the next au­tore­gres­sive step, they are es­sen­tially part of an ex­tended for­ward pass, go­ing mul­ti­ple times through the model. This makes them ap­prox­i­mately as difficult to faith­fully trans­late into nat­u­ral lan­guage as any other ar­bi­trary vec­tor in la­tent space at an ar­bi­trary layer of the trans­former; this is not only an un­solved prob­lem, but some re­searchers say it “may be doomed”.\nPriorities\nBe­cause of its in­ter­pretabil­ity difficulty, Neu­ralese opens up a much larger at­tack sur­face for steganog­ra­phy and strate­gic de­cep­tion in CoT. \n\nIt is a pri­or­ity to avoid ap­ply­ing strong op­ti­miza­tion pres­sures to CoT, since in­ter­pretable CoT is one of our main lev­ers in AI safety right now.\n\nIt is a pri­or­ity to avoid im­ple­ment­ing Neu­ralese CoT on fron­tier mod­els be­cause that re­moves es­sen­tially all of our abil­ity to in­ter­pret their rea­son­ing.\n\nIn the event of wide­spread adop­tion of Neu­ralese CoT, it is a pri­or­ity to de­velop in­ter­pretabil­ity mechanisms that are at least as ca­pa­ble at de­tect­ing de­cep­tive be­hav­iors in CoT as SOTA meth­ods for in­ter­pret­ing nat­u­ral-lan­guage CoT. How­ever even if such in­ter­pretabil­ity mechanisms are de­vel­oped, they likely also gen­er­al­ize to more ac­cu­rately in­ter­pret­ing nat­u­ral lan­guage CoT than our cur­rent tech­niques and thus are more use­ful for en­sur­ing ro­bust safety when used on nat­u­ral lan­guage.\n\nTh­ese pri­ori­ties fit into a much larger AI safety agenda; de­pend­ing on how labs con­tinue their de­vel­op­ment, safety re­search on Neu­ralese may be one of the many pre­req­ui­sites to en­sur­ing safe AGI.\n\n^\nWe can see the benefits of this par­allelism even with­out CoT. For ex­am­ple, we see benefits when mod­els first out­put many ”.” to­kens, and then pro­duce an an­swer.\n\n^\nI won’t list them, be­cause I have a policy of not pub­li­cly point­ing out ways to im­prove fron­tier model ca­pa­bil­ities in ways that don’t have a worth­while safety benefit as well.\n\n^\nA pos­si­bly mo­ti­vat­ing fic­tional ex­am­ple is how Baseline, the lan­guage of dath ilan, en­codes con­cepts like “de­ci­sion-the­o­retic-coun­ter­fac­tual-threat-branches-of-re­al­ity” in three syl­la­bles in­stead of the twenty that English uses. Not all ab­strac­tions are nat­u­ral for all in­tel­li­gences.",
      "pubDate": "Wed, 12 Mar 2025 16:29:31 +0000",
      "isoDate": "2025-03-12T16:29:31.000Z",
      "author": "Alice Blair",
      "guid": "qehggwKRMEyWqvjZG",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "Cautions about LLMs in Human Cognitive Loops by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/apCnFyXJamoSkHcE4/cautions-about-llms-in-human-cognitive-loops",
      "description": "soft pre­req­ui­site: skim­ming through How it feels to have your mind hacked by an AI un­til you get the gen­eral point. I’ll try to make this post read­able as a stan­dalone, but you may get more value out of it if you read the linked post.\nThanks to Claude 3.7 Son­net for giv­ing feed­back on a late draft of this post. All words here are my own writ­ing. Cau­tion was ex­er­cised in in­te­grat­ing Claude’s sug­ges­tions, as is the­matic.\nMany peo­ple right now are think­ing about the hard skills of AIs: their abil­ity to do difficult math, or code, or ad­vance AI R&D. All of these are im­mensely im­por­tant things to think about, and in­deed I spend much of my time think­ing about those things, but I am here right now to talk about soft skills of AIs, so that fewer of us end up with our brains hacked by AI.\nA Mo­ti­vat­ing Example\nsoft pre­req­ui­site for this sec­tion: Su­per­stim­uli and the Col­lapse of Western Civ­i­liza­tion.\nSu­per­stim­uli are stim­uli that are much more in­tense than those in the en­vi­ron­ment where hu­mans evolved, like how a candy bar is much denser in tasty things like sug­ars and fats than any­thing in na­ture.\nMany hu­mans spend much of their time fol­low­ing their lo­cal dopamine gra­di­ent, mov­ing to the next most ex­cit­ing thing in their im­me­di­ate vicinity: they see some­thing ap­peal­ing, they go do it. They can also be strate­gic about things and can look to the global dopamine gra­di­ent, fur­ther away in space and time, when they need to, but this of­ten re­quires non­neg­ligible willpower. (e.g. Stan­ford Marsh­mal­low Ex­per­i­ment ).\nOc­ca­sion­ally, some­one gets swept up in a dopamine gra­di­ent too strong to re­sist, even with good rea­sons to stop. They over­dose on drugs, they overeat un­healthy foods, they play video games for days un­til they die. And those are just some of the strongest dopamine gra­di­ents that hu­mans have cre­ated.\nWe’re see­ing the be­gin­ning of the rise of cheap AI video gen­er­a­tion. It’s all over Youtube[1]. It’s not good, but it’s mes­mer­iz­ing. It’s bizarre, and it scratches some itch for some peo­ple. You can look it up if you’re re­ally mor­bidly cu­ri­ous, but I won’t link any­thing, since the whole point of this sec­tion of the post is “don’t get stuck in strong dopamine gra­di­ents from AI-gen­er­ated con­tent.” When (not if) this tech­nol­ogy does get Good, then we have cheap con­tent gen­er­a­tion with a pow­er­ful op­ti­mizer be­hind it, pre­sum­ably trained well enough to grok what keeps hu­mans en­gaged.\nMaybe they already ex­ist, maybe they will only ex­ist later, but at some point I ex­pect there to be peo­ple who spend sig­nifi­cant time caught in loops of highly stim­u­lat­ing AI-op­ti­mized con­tent be­yond what is available from hu­man cre­ators. This pre­dic­tion re­lies on a few spe­cific things:\n\nFast Feed­back Loops: AI con­tent cre­ators can cre­ate videos in a given style and for a given au­di­ence faster than an in­di­vi­d­ual can watch them. Th­ese mod­els can quickly pick up on cues to go from “un­en­ter­tain­ing” to “su­per­stim­u­lus” much faster than hu­man con­tent cre­ators can. Video gen­er­a­tion is cur­rently ex­pen­sive, but I ex­pect it to get much cheaper as AI his­tor­i­cally has.\n\nManag­ing a Com­plex Re­ward Sig­nal: The best hu­man con­tent cre­ators have a strong in­tu­ition for how a given piece will be re­ceived, based on their ex­pe­rience both of op­ti­miz­ing for “the al­gorithm” and of in­ter­act­ing with hu­mans. The set “all hu­mans who at least semi-reg­u­larly con­sume Youtube” is very large, and even the most sea­soned cre­ators are at a dis­ad­van­tage, both from their slow feed­back loops and from their limited abil­ity to han­dle the sheer com­plex­ity of the prob­lem. Mean­while, AI has shown a re­mark­able abil­ity to fit wide va­ri­eties of struc­tured data and match pat­terns that hu­mans have a hard time pick­ing up on. In the limit, this risk doesn’t only ap­ply to the iPad-bound chil­dren who have been watch­ing 12 hours of Youtube ev­ery day since they were 2 years old, but also to the peo­ple who watch Youtube some­times, the peo­ple who have strong willpower but oc­ca­sion­ally watch a video that par­tic­u­larly piques their in­ter­est. In the limit, some of those peo­ple get sucked into what­ever highly stim­u­lat­ing me­dia they find, and some of the most sus­cep­ti­ble peo­ple don’t come out.\n\nIn this ex­am­ple, we see a util­ity max­i­mizer which can be fooled by dopamine gra­di­ents (hu­man), a recom­men­da­tion al­gorithm, and a util­ity max­i­mizer that has ex­actly one com­plex goal (con­tent gen­er­a­tor that max­i­mizes en­gage­ment met­rics). The op­ti­miza­tion be­tween these is mostly self-re­in­forc­ing; the only forces that push away from the sta­ble state of “~ev­ery­one is watch­ing su­per­stim­u­lat­ing videos un­til they die” is the limits on how good the con­tent gen­er­a­tors and recom­menders are and the willpower of the hu­mans to do things like eat and get money. I am not con­fi­dent rely­ing on ei­ther of those things, given the in­creas­ing scal­ing in AI sys­tems and the small amount of willpower that most peo­ple have ac­cess to.\nOver-In­te­gra­tion of AI Cognition\nRe­lated non-pre­req­ui­site: AI De­cep­tion: A Sur­vey of Ex­am­ples, Risks, and Po­ten­tial Solutions\nThe pre­vi­ous sec­tion de­tails a failure mode that is tar­geted to­wards av­er­age-willpower, av­er­age-agency peo­ple. How­ever, the high-willpower, highly agen­tic peo­ple are still at risk. Th­ese peo­ple want to do things, and they re­al­ize that they can pick up these gi­ant piles of util­ity by us­ing AIs as an ex­ter­nal brain to en­hance their cog­ni­tion and agency even fur­ther. The more work you can suc­cess­fully offload to AIs, the more room you have to be agen­tic and the more util­ity you can pick up.\nBut we can­not trust AIs to be a re­li­able ex­ter­nal brain to us, just as we can­not re­li­ably trust hu­mans with that. Say you talk to a friend about some­thing com­plex, you two work through the rea­son­ing to­gether, and you come to a con­clu­sion that seems right, given the rea­son­ing you just went through. You go home that night, let your mind wan­der, and you re­al­ize that one of the steps in the rea­son­ing is sub­tly off upon fur­ther in­spec­tion. You have a re­flex to gen­er­al­ize, and you no­tice that any of the other steps in rea­son­ing that you skimmed over could also be similarly com­pletely wrong, and they could be harder to dis­en­tan­gle than the one you just ran into.\nLLMs are at the level where they can not only pro­duce mis­takes that mis­lead smart-but-not-om­ni­care­ful peo­ple in that way, but they can also pro­duce in­ten­tional de­cep­tions that mis­lead those peo­ple as well! I tested this: It took a bit of prompt­ing and back-and-forth, but I was able to get o3-mini-high to gen­er­ate de­cep­tive ar­gu­ments about ML (my area of most ex­pe­rience) that I couldn’t find a flaw in, even know­ing there was a flaw, even af­ter see­ing a hint about which step of rea­son­ing it was in. Ad­mit­tedly, it was not in an area of ML that I was par­tic­u­larly fa­mil­iar with.[2] I later prompted try­ing to get it to provide similarly de­cep­tive ar­gu­ments for ar­eas that I know very well, and it failed. I think that “can in­ten­tion­ally cre­ate suc­cess­fully de­cep­tive-to-me ar­gu­ments in all but my rel­a­tively spe­cific ex­per­tise” is a scar­ily high level of ca­pa­bil­ities already, but I also ex­pect that in the next gen­er­a­tion or two of mod­els, it will be able to pull this trick much more seam­lessly in prac­ti­cally all do­mains.\nIf you are try­ing to pick up a lot of util­ity, you might try to offload a lot of cog­ni­tion to LLMs by tightly in­te­grat­ing them into your think­ing to mas­sively ac­cel­er­ate what­ever work you do. In cases where the LLMs are al­igned, this Just Works and you get the util­ity, but if you don’t have that guaran­tee of safety, you sud­denly have a large at­tack sur­face for sub­tle de­cep­tion like I’ve de­scribed. Here are some other re­lated failure modes:\n\nMis­di­rect­ing your at­ten­tion to some sub­set of the things you’re work­ing on, by\n\nTalk­ing more about that sub­set/​Fram­ing things so that your at­ten­tion goes there\n\nSelec­tively sand­bag­ging on some set of tasks, so that your at­ten­tion goes to the tractable-seem­ing prob­lems instead\n\n\n\n(for situ­a­tions in which the LLM han­dles some mem­ory) strate­gi­cally gaslight­ing you on minute de­tails, mod­ify­ing de­tails and re­la­tion­ships be­tween de­tails Ad­di­tion­ally, even in situ­a­tions where the LLM isn’t tightly in­te­grated into your cog­ni­tive loop, there’s always the clas­sic strat­egy of pre­sent­ing a mono­lithic ar­gu­ment for e.g. why it’s a re­ally good idea to let it out of its box or some­thing else that you wouldn’t com­mit in ad­vance to do­ing.\n\nDoes this End Up Mat­ter­ing in Real Life?\nRight now, at least, it seems rather un­likely that LLMs are se­cretly be­ing de­cep­tive and perform­ing these sub­tle ma­nipu­la­tions, even though they are in prin­ci­ple ca­pa­ble of it in most do­mains. What rea­sons are there for think­ing about this?\nThere is of course the Se­cu­rity Mind­set rea­son­ing that you are un­com­fortable with let­ting a coun­ter­fac­tual ad­ver­sary into your cog­ni­tive pro­cesses, and you are un­com­fortable with there be­ing a way for such a coun­ter­fac­tual ad­ver­sary to get in, even in prin­ci­ple.\nHow­ever, there is also the fact that the ap­pear­ance of se­ri­ous de­cep­tion prob­lems is weighted much more to­wards the later end of AGI de­vel­op­ment, where mod­els are be­com­ing situ­a­tion­ally aware and strate­gic (see #13 in AGI Ruin: A List of Lethal­ities). Work­ing on this now is im­por­tant work for prepar­ing our fu­ture selves. Fur­ther, this is a ca­pa­bil­ity that is very plau­si­bly some­thing that shows up af­ter situ­a­tional aware­ness and be­fore ASI, as it may be very use­ful to de­ceive hu­mans in or­der to get bet­ter op­por­tu­ni­ties for re­cur­sive self-im­prove­ment.\nFi­nally, we can pre­dict that the world is go­ing to get very weird in the next few years be­fore ASI. Weird in tech­nolog­i­cal ad­vance­ments, but also very quickly weird and tense in poli­tics as the wider world wakes up to what is hap­pen­ing. If we ex­pect to see any na­tion use AIs for a mass per­sua­sion cam­paign, for ex­am­ple, then it is even more im­por­tant to quickly be­come ro­bust to AIs at­tempt­ing to dis­rupt your cog­ni­tive loops.\nIn Search of Shovel-Ready Mitigations\nThere are some read­ers who will see this post and au­to­mat­i­cally keep these failure modes in mind and spend their time to cau­tiously re­ex­am­ine the im­por­tant as­pects of their LLM us­age. There are yet many more read­ers who would greatly benefit from some ready-to-go reme­dies. The only perfect reme­dies are “solve al­ign­ment” and “live in an in­ter­net-free bunker and never let AIs in­fluence your cog­ni­tion in any way,” and things on this list are not in­tended to fill that gap. This list is not in­tended to be ex­haus­tive; you are in fact highly en­couraged to add to this list.\n\nIf you’re work­ing on some­thing that is not highly com­plex: talk­ing to a small, trusted model be­fore you talk to an un­trusted model.\n\nWeak­ness: “trusted” mod­els are not se­cure sys­tems, they just do not de­ceive their users in a strate­gi­cally mean­ingful way by de­fault.\n\n\n\nPre­dict ways that you might up­date or classes of in­for­ma­tion that you might re­ceive af­ter in­ter­act­ing with a po­ten­tially de­cep­tive AI. Treat these as your “al­lowed courses of ac­tion” and if your ac­tual tra­jec­tory is out­side of those pre­dic­tions, re­view your rea­son­ing with ex­tra scrutiny.\n\nWeak­ness: the AI might bias you within your space of al­lowed op­tions. This tech­nique also com­pletely falls apart past a cer­tain ca­pa­bil­ity level, since your com­mit­ment to your ini­tial op­tions is some­thing that suffi­ciently ad­vanced AI can break.\n\n\n\nPri­ori­tize ac­tions re­sult­ing from AI in­ter­ac­tion that are cheaply re­versible; be more sus­pect of you should buy a house” than “you should go for a walk,” even if the ar­gu­ments for both sound the same amount con­vinc­ing on the ob­ject level, and you felt like your start­ing cre­dence in both was similar.\n\nWeak­ness: this strat­egy can eas­ily bias you into in­ac­tion, es­pe­cially in times when the most benefi­cial course is to do ir­re­versible things.\n\n\n\nMake the model ex­press it­self in higher re­s­olu­tion and give ex­plicit epistemic jus­tifi­ca­tions: it’s harder to de­ceive when that de­cep­tion also has to be grounded in ac­cu­rate pre­dic­tions about the world.\n\nWeak­ness: you only ever get to see one coun­ter­fac­tual branch, the con­se­quences of one chain of ac­tions and not their al­ter­na­tives. It is very fea­si­ble to de­cep­tively pre­sent epistemics re­gard­ing a path that the user will not take.\n\n\n\nCon­sult mul­ti­ple mod­els at the same ca­pa­bil­ity level, prefer­ably ones from differ­ent sources and that have no way of com­mu­ni­cat­ing with each other. Pay close at­ten­tion to their dis­agree­ments.\n\nWeak­ness: this as­sumes two things that may not re­li­ably hold: you have ac­cess to mul­ti­ple mod­els at the same level of use­ful­ness and if they were to de­ceive you, they’d do so in differ­ent ways, rather than con­ver­gently in­stru­men­tal/​acausally co­op­er­a­tive ways. Fur­ther, this is plau­si­bly a good way to end up just be­liev­ing whichever de­cep­tive ar­gu­ment is most com­pel­ling, rather than the truth.\n\n\n\n^\nI’m us­ing Youtube as an ex­am­ple, but fill in the gaps with video games, so­cial me­dia, pornog­ra­phy, etc. if you find those more com­pel­ling. This ar­gu­ment holds for most (if not all) of the su­per­stim­uli that the in­ter­net has to offer. \n\n^\nHighly the­o­ret­i­cal ML, stuff about the be­hav­ior of ideal­ized limit­ing net­works that don’t ac­tu­ally rep­re­sent most real use cases. I had to Google some stuff for the ex­am­ple o3-mini-high gave. I’ve in­ter­acted a bit with this area, but for sim­pler ex­am­ples that out­put foun­da­tional facts like “net­works un­der these ideal­ized con­di­tions are uni­ver­sal ap­prox­i­ma­tors for this class of func­tions.”",
      "pubDate": "Sun, 02 Mar 2025 19:53:10 +0000",
      "isoDate": "2025-03-02T19:53:10.000Z",
      "author": "Alice Blair",
      "guid": "apCnFyXJamoSkHcE4",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "Absorbing Your Friends’ Powers by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/J6gKFimPwdLc8jmhc/absorbing-your-friends-powers",
      "description": "Motivation\n\nRichard Ham­ming was a math­e­mat­i­cian who worked at Bell Labs dur­ing the 1940s-1970s. He had a habit of sit­ting down with sci­en­tists in other fields and ask­ing them “What are the im­por­tant prob­lems of your field?” After they ex­plained their field’s most im­por­tant open prob­lem, he would ask them: why aren’t you work­ing on that?\n\n-Ap­pendix: Ham­ming Ques­tions, from the CFAR Handbook\nThis post starts off by ask­ing an analo­gous pair of ques­tions:\n\nWho is the most skil­led/​gen­er­ally ca­pa­ble/​cog­ni­tively pow­er­ful per­son you know?\n\nand subsequently\n\nWhy don’t you talk to them more?\n\n(If you did not already pause to ask your­self those ques­tions and come up with some sort of an­swer, I recom­mend you take a minute or so to do it.)\nI want to be­come stronger. I want to not only ab­sorb the pow­ers of those around me, but go on to sur­pass them. I do this be­cause I have some­thing to pro­tect, and right now it’s look­ing like it’ll re­quire a truly ex­traor­di­nary effort in or­der to pro­tect the things I care about in the medium and long term. So here’s one of the things I do about it.\n1. Find the most skil­led/​gen­er­ally ca­pa­ble/​cog­ni­tively pow­er­ful per­son you know.\nIf there are more than one of them who seem ob­vi­ously highly skil­led, then choose all of them. This pro­cess is eas­ier if the peo­ple cho­sen in this step are at least a level above you, but this is not strictly nec­es­sary. Peo­ple have non-over­lap­ping skil­lsets, so a vast ma­jor­ity of pairs of peo­ple have at least some­thing to ab­sorb from each other. Still, we’re try­ing to level up quickly, which means pick­ing the per­son who you can ab­sorb the most power from.\n2. Talk to them more. Ab­sorb their pow­ers.\nThis can be as sim­ple as “you seem com­pe­tent, how did you do X thing/​come up with X idea?” This can feel weird and in­duce some anx­iety since it goes against the so­cial grain in many cir­cles, but it is gen­er­ally flat­ter­ing enough to the re­cip­i­ent that it out­weighs those con­sid­er­a­tions. In ra­tio­nal­ist cir­cles, this is a perfectly nor­mal-seem­ing ques­tion, of course, so no need to worry if you’re in such a cir­cle. Other ideas for ques­tions:\n\nAsk what they’re track­ing in their head.\n\nAsk what their most use­ful cog­ni­tive skill is.\n\nAsk what les­sons they’ve learned from peo­ple at a level above theirs.\n\nAsk them for ad­vice on some­thing you’re con­sid­er­ing.\n\nAsk them what they do to level up and com­pare this to your strate­gies.\n\nPay at­ten­tion to the small ways they tackle ques­tions, the lit­tle choices they make with­out re­al­iz­ing. This is how to learn the things that are hard to ex­plic­itly teach.\n\nLatch onto them. Ask them as many ques­tions as you can man­age with­out both­er­ing them. No­tice your con­fu­sion about why they are the way they are, and then seek to de­stroy your con­fu­sion.\nThen in­ter­nal­ize it. Un­der­stand what it’s like to have the pow­ers that they have, and then use them your­self. Don’t try to be­come ex­actly them; be­come a lev­el­led up ver­sion of you.\n3. Recurse\nAsk them the first mod­ified Ham­ming Ques­tion at the be­gin­ning of this post:\n\nWho is the most skil­led/​gen­er­ally ca­pa­ble/​cog­ni­tively pow­er­ful per­son you know? \n\nand sub­se­quently \n\nCan you put me in touch with that per­son?\n\nYou can also do this by find­ing your way into the spaces that the per­son you’re ab­sorb­ing power from hangs out in, and then find new peo­ple from there. Both are solid strate­gies that have caused me to meet very in­for­ma­tive new peo­ple to ab­sorb power from.",
      "pubDate": "Thu, 30 Jan 2025 02:32:27 +0000",
      "isoDate": "2025-01-30T02:32:27.000Z",
      "author": "Alice Blair",
      "guid": "J6gKFimPwdLc8jmhc",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "Alice Blair’s Shortform by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/eukutrwGBPutoQoyM/alice-blair-s-shortform",
      "description": "",
      "pubDate": "Mon, 27 Jan 2025 23:25:10 +0000",
      "isoDate": "2025-01-27T23:25:10.000Z",
      "author": "Alice Blair",
      "guid": "eukutrwGBPutoQoyM",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "AI Strategy Updates that You Should Make by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/mZH23GpAAW8jS782a/ai-strategy-updates-that-you-should-make",
      "description": ".mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n\nor: “Things That I Keep Tel­ling AI Peo­ple Around Me, So I’m Just Writ­ing A Big Post About Them.” I think it’s re­ally valuable for peo­ple to think about AI strat­egy, even if that’s not their main job, since it is use­ful for in­form­ing what their main job should be.\nThere will be a later post ti­tled some­thing like “Emo­tional Up­dates on AI that You Should Make”. This is not that. Things are chang­ing fast enough that I want to get one or the other out quickly, and be­sides, emo­tion should fol­low be­lief, so this one is com­ing first.\n[Epistemic sta­tus: I ex­pect most of the things I pre­dict here to turn out cor­rectly since most of the rea­son­ing feels pretty straight­for­ward, and I mark es­pe­cially spec­u­la­tive things as such.]\nA good thing to keep in mind: if you can pre­dict that fu­ture-you will make a cer­tain up­date, just make it now in­stead.\nModels\no3\nIf you’ve made it to this post, you’ve prob­a­bly heard about o3. Nonethe­less, here’s the sum­mary. Be­sides just be­ing par­tic­u­larly good at math and [what­ever-it-is that ARC-AGI mea­sures], the cod­ing bench­marks, in­clud­ing the fact that o3 gets higher elo on code­forces than all but one OpenAI em­ployee, in­di­cate that we’re solidly ap­proach­ing the be­gin­ning of Re­cur­sive Self-Im­prove­ment. It’s very ex­pen­sive to run at this scale, but it is clearly go­ing to get cheaper (see Up­dates from Models).\nDeepseek-v3\nRe­port­edly, it took $5.5 mil­lion to train a LLM that performs on par with the ~May 2024 fron­tier. Anec­do­tally, it seems like it’s worse than Claude 3.6 Son­net, but not by huge amount. It feels like it’s in a similar tier, but not quite reach­ing the same level. The bench­marks turn out pretty similar to 3.6. It’s also very cheap to run, com­pared to other mod­els at this level, in large part due to its in­cred­ibly small size for a fron­tier model. The rest is due to hard­ware op­ti­miza­tions that Deepseek performed. Notably, it’s open source.\n(EDIT: a reader pointed out that the to­tal costs were likely much higher than this, ac­count­ing for wages, R&D, etc. This $5.5 mil­lion num­ber is some­what mis­lead­ing in some re­spects. Also, a pre­vi­ous ver­sion of the above para­graph eval­u­ated Deepseek-v3 and Claude 3.6 Son­net as be­ing at similar lev­els of power, which I re­al­ized was an over­sim­plifi­ca­tion.)\nDeepseek-R1\nJust as GPT-4o be­came o1 with RL on CoT, Deepseek-v3 be­came Deepseek-R1, a rea­son­ing model which is, by Zvi’s es­ti­mate, 10x cheaper for similar qual­ity out­puts to o1. Fur­ther, you can see the chain of thought, which is both very weird and of­ten use­ful. Be­ing able to see the rea­son­ing that goes into a claim makes it much more di­gestible, and it makes it much eas­ier to de­tect and sal­vage when the model makes a mis­take.\nDistillations\nFur­ther, Deepseek was able to perform knowl­edge dis­til­la­tion from R1 to var­i­ous smaller mod­els, get­ting very im­pres­sive re­sults (page 14 of the pa­per).\nUp­dates from Models\nAs per usual, go out and get your util­ity from these mod­els. They’re pow­er­ful and only ever get­ting moreso. Peo­ple of­ten un­der-up­date on this fact and don’t think of cre­ative ways to offload more and more cog­ni­tive tasks to LLMs and they get less util­ity be­cause of it.\nTh­ese re­sults show us a few differ­ent things about strat­egy, as well:\nFirst, how­ever fast you think OpenAI is scal­ing based off of the o3 news, that’s an un­der­es­ti­mate. Just make the up­date now so you don’t have to do it later. Why? Most of the US AGI com­pa­nies have a mas­sive com­pute over­hang now, be­cause of Deepseek. Even though OpenAI has o3 and that’s more perfor­mant than any­thing Deepseek is do­ing, 4o (the likely base model un­der o3) is nowhere nowhere near as effi­cient as Deepseek-v3 or the R1 dis­til­la­tions, and so there’s a lot of room to take ad­van­tage of the new effi­ciency and get higher perfor­mance with­out need­ing much more com­pute or money. If you put OpenAI’s bud­get into Deepseek’s meth­ods (do their par­tic­u­lar style of MoE, do RL on CoT, then knowl­edge dis­til­la­tion), you’re go­ing to get im­prove­ment out the other end, and prob­a­bly a pretty siz­able im­prove­ment with­out much ad­di­tional effort be­yond what Deepseek did.\nSe­cond is that open-weight mod­els are get­ting a lot more se­ri­ous. Any­thing that’s out in the open is out for­ever, and so is the jailbro­ken ver­sion of it, since our cur­rent “al­ign­ment tech­niques” are so easy to undo. The open weight fron­tier will never be any worse than R1, and it can only build on that. If Chi­nese AI com­pa­nies are try­ing to catch up to the US fron­tier, then a plau­si­bly re­ally good way to do it is to get peo­ple re­ally ex­cited about some open fron­tier mod­els and then take ad­van­tage of the open source com­mu­nity to ac­cel­er­ate them fur­ther. Epoch shows that closed mod­els have been los­ing their lead over open mod­els for some time now, and Deepseek-v3 and R1 only fur­ther this trend.\nThird is that, if you are still work­ing un­der a strat­egy that as­sumes we don’t en­ter a re­cur­sive self-im­prove­ment+AI R&D au­toma­tion loop, it’s a bit too late. Either have a good rea­son why that loop will stop de­spite all the mas­sive mon­e­tary in­cen­tives for it to keep go­ing, or ditch that plan.\nFourth, if your strat­egy re­lies on not giv­ing China or any US ad­ver­saries enough com­pute to make fron­tier mod­els, ditch that too.\nGeopolitics\nThe EO\nTrump re­pealed the Bi­den AI EO. As I un­der­stand it, this ac­tion doesn’t dis­man­tle the US AISI, but it does re­move the man­date for the AISI to do much use­ful stuff. I don’t find it max­i­mally clear where the re­peal is com­ing from, but most of my prob­a­bil­ity mass is on it be­ing an anti-safety move for the pur­pose of fur­ther ac­cel­er­at­ing US AI progress.\nStargate\nPeo­ple keep call­ing this the AGI Man­hat­tan Pro­ject. It is not the AGI Man­hat­tan Pro­ject. It is an an­nounce­ment of tech peo­ple in­vest­ing a lot in AI, and Don­ald Trump hap­pened to be there. The cur­rent plan is to in­vest $100 billion into AI in­fras­truc­ture im­me­di­ately, and $500 billion over the next four years. At pre­sent, there is no (an­nounced) USG fund­ing go­ing into it. Man­i­fold thinks that the likely mon­e­tary out­put is very bi­modal, ei­ther do­ing much less than promised or do­ing much more than promised. \n\n\n\t\t\t\n\nWhile this mar­ket is cur­rently pretty low-vol­ume, I gen­er­ally agree with the dis­tri­bu­tion at the time of writ­ing.\nChi­nese Star­gate?\nTwo days af­ter the Star­gate an­nounce­ment, the Bank of China re­leased this. Trans­la­tion[1] (by Claude 3.6 Son­net). The gist is that Bank of China is say­ing they’ll in­vest ≥$140B in AI in­fras­truc­ture over the next five years.\nUp­dates from News\nAlthough Star­gate is not a Man­hat­tan pro­ject, it very well might be­come a Man­hat­tan Pro­ject; the US has a lot of rea­sons to not want ran­dom com­pa­nies mak­ing su­per­in­tel­li­gence. Leopold put it well: “Imag­ine if we had de­vel­oped atomic bombs by let­ting Uber just im­pro­vise.” If ever there were a nice con­ve­nient or­ga­ni­za­tion that the US gov­ern­ment would like to ab­sorb or par­tially ab­sorb, this will prob­a­bly be one of them, given that they are poised to Do The Thing and Make The AGI Hap­pen. This seems es­pe­cially likely be­cause the fact that this an­nounce­ment was with Trump means that there’s some level of talk and co­or­di­na­tion be­tween tech and gov­er­nance. But also, Trump’s words and out­ward sig­nals are not his­tor­i­cally very cor­re­lated with his ac­tions, so it’s very hard to use them as more than weak ev­i­dence for his strat­egy.\nStill, it seems pretty clear that the gov­ern­ment is treat­ing the world like we’re in for an arms race that we must win in or­der to bring about the so-called “golden age”.\nIn both the Star­gate and Bank of China an­nounce­ments, it’s not ex­actly clear what con­cretely, definitely hap­pens next, other than “lots of money goes into [AI In­fras­truc­ture]”. I pre­dict that this is only the be­gin­ning of things ramp­ing up be­tween the US and China. I also pre­dict that we might see other fron­tier AI labs pop­ping up in China, since right now it’s ba­si­cally just Deepseek at the fron­tier, and there’s about to be a lot more fund­ing to go around (if the Bank of China memo is to be be­lieved).\nIf you’re work­ing un­der a strat­egy that re­lies on the US and China not en­ter­ing a full-on AI arms race, you’d bet­ter have a rea­son why this cur­rently-build­ing arms race is just go­ing to stop, oth­er­wise ditch the strat­egy. If you’re work­ing un­der a strat­egy that re­lies on the de­fault po­si­tion of the US gov­ern­ment be­ing cau­tious about ASI by de­fault, ditch that strat­egy.\nMacro-Scale Strat­egy Updates\nChina\nIf China wakes up to the pos­si­bil­ity of an AGI race (which it seems like it is, from the Bank of China source), then at some point, their fron­tier mod­els must be closed, es­pe­cially if they gain a ca­pa­bil­ities lead. It’s just not strate­gi­cally sound to send over AGI weights to the per­son you’re in an AGI arms race with (and to ev­ery­one in the world). There­fore, con­di­tional on us be­ing in an arms race sce­nario be­tween China and the US, it makes sense to pre­dict that Chi­nese mod­els will stop be­ing open source at some point around when the Chi­nese fron­tier meets the US fron­tier, break­ing the strong pat­tern we’re see­ing now of open sourc­ing mod­els. If you’re work­ing un­der a strat­egy that as­sumes that the US main­tains a lead over China in the AGI race and never loses it, se­ri­ously ques­tion that as­sump­tion, given re­cent Chi­nese ac­cel­er­a­tion.\nI’m re­ally in­ter­ested in writ­ing a post some­time soon about what can be gained from pre­dict­ing this pat­tern vi­o­la­tion in ad­vance.\nUS\nBe­fore the Trump pres­i­dency be­gan, I was hear­ing a lot of am­bi­guity about what it meant for AI strat­egy. Peo­ple don’t quite know to pre­dict his ac­tions given his words, nor do they even know how to pre­dict his words. Now, we know that we’re prob­a­bly in the arms race world (and have been able to see it com­ing for a lit­tle while now). We know that we’re prob­a­bly in a world where some sort of AGI com­pany na­tion­al­iza­tion hap­pens, for both the US and China.\nConclusion\nDo not be­come at­tached to strate­gies you may not want. Don’t let your plans be stuck in the past.\n\n^\n1 Trillion Yuan! Pro­vid­ing Spe­cial Com­pre­hen­sive Fi­nan­cial Sup­port to Aid AI In­dus­try Chain Development\nAc­cord­ing to the “Bank of China’s Ac­tion Plan to Sup­port AI In­dus­try Chain Devel­op­ment,” Bank of China plans to provide spe­cial­ized com­pre­hen­sive fi­nan­cial sup­port to­tal­ing no less than 1 trillion yuan to var­i­ous en­tities across the AI in­dus­try chain over the next five years. This in­cludes no less than 300 billion yuan in com­bined equity and debt fi­nanc­ing, along with es­tab­lish­ing spe­cial­ized in­sti­tu­tional safe­guards al­igned with AI tech­nolog­i­cal in­no­va­tion to serve the fi­nan­cial needs across all links in the in­dus­try chain.\nEm­pow­er­ing Na­tional Scien­tific and Tech­nolog­i­cal Self-Reli­ance As the first bank to es­tab­lish a sup­port mechanism for ma­jor sci­en­tific and tech­ni­cal pro­jects, Bank of China has launched “1+1+N” full-cy­cle ser­vices. With sup­port from rele­vant ministries, Bank of China has es­tab­lished di­rect co­op­er­a­tion with ma­jor AI tech­nol­ogy pro­jects, pro­vid­ing “one-stop” cus­tomized fi­nan­cial ser­vices cov­er­ing “ba­sic re­search-achieve­ment trans­for­ma­tion-in­dus­trial ap­pli­ca­tion” for “N” com­pa­nies in­volved in in­no­va­tive tech­nol­ogy, con­tin­u­ously im­prov­ing the sci­en­tific and tech­nolog­i­cal fi­nan­cial sys­tem mechanism that matches tech­nolog­i­cal in­no­va­tion.\nServ­ing AI Fac­tor Sup­ply Bank of China fully lev­er­ages its com­pre­hen­sive fea­tures to strengthen the com­put­ing power and data sup­ply foun­da­tion for the AI in­dus­try. Through di­ver­sified fi­nan­cial tools in­clud­ing equity, loans, bonds, in­surance, and leas­ing, it em­pow­ers the de­vel­op­ment of in­tel­li­gent com­put­ing in­fras­truc­ture. Fo­cus­ing on na­tional com­put­ing hub node plan­ning, it sup­ports the con­struc­tion of in­tel­li­gent com­put­ing cen­ters and sup­port­ing fa­cil­ities and park in­fras­truc­ture. It pro­vides fi­nan­cial guaran­tees such as prop­erty in­surance and com­pre­hen­sive in­surance for first (set) ma­jor tech­ni­cal equip­ment to en­hance en­ter­prise risk con­trol ca­pa­bil­ities.\nBoost­ing AI Tech­ni­cal In­no­va­tion Bank of China pro­vides differ­en­ti­ated fi­nan­cial ser­vices through­out the life­cy­cle for tech­ni­cal in­no­va­tion en­ter­prises in mod­els and al­gorithms. It has cre­ated the “BOC M&A+” one-stop ser­vice sys­tem to pro­mote the in­te­gra­tion and up­grade of AI tech­nol­ogy with in­dus­trial re­sources. By in­te­grat­ing BOC Group’s AIC equity in­vest­ment fund and the do­mes­tic and in­ter­na­tional in­vest­ment bank­ing ad­van­tages of BOC In­ter­na­tional and BOC Se­cu­ri­ties, it es­tab­lishes an in­te­grated “equity+com­mer­cial bank­ing+in­vest­ment bank­ing” ser­vice sys­tem to help key core tech­nol­ogy en­ter­prises ac­cess cap­i­tal mar­ket fi­nanc­ing chan­nels and cul­ti­vate in­dus­try chain “uni­corns” and listed com­pa­nies.\nPro­mot­ing AI Sce­nario Ap­pli­ca­tions Bank of China in­creases sup­port for AI tech­nol­ogy demon­stra­tion ap­pli­ca­tions. It opens up and cre­ates in­tel­li­gent mar­ket­ing, in­tel­li­gent op­er­a­tions, and in­tel­li­gent risk con­trol ap­pli­ca­tion sce­nar­ios. It builds up­stream and down­stream in­dus­try chain con­nec­tion plat­forms, cre­at­ing differ­en­ti­ated sup­ply chain fi­nan­cial ser­vice solu­tions for differ­ent sce­nar­ios. It sup­ports the growth of new tracks such as “AI+robotics,” “AI+low-al­ti­tude econ­omy,” “AI+bio­man­u­fac­tur­ing,” and “AI+new ma­te­ri­als” to cul­ti­vate new de­vel­op­ment mo­men­tum. Lev­er­ag­ing Bank of China’s global op­er­at­ing ad­van­tages, it pro­vides pro­fes­sional cross-bor­der fi­nan­cial sup­port for AI en­ter­prises’ “go­ing out” and “bring­ing in” through the “sin­gle point ac­cess, global re­sponse” plat­form.\nBank of China will use the AI in­dus­try chain ser­vice as a pi­lot to con­struct a com­pre­hen­sive, multi-level fi­nan­cial ser­vice sys­tem, con­tin­u­ously cre­at­ing new paradigms in tech­nol­ogy fi­nance, fully sup­port­ing key core tech­nolo­gies, serv­ing the de­vel­op­ment of the en­tire AI in­dus­try chain, and pro­mot­ing high-level cir­cu­la­tion of “tech­nol­ogy-in­dus­try-fi­nance” to con­tribute sus­tained fi­nan­cial mo­men­tum for build­ing a mod­ern in­dus­trial sys­tem and pro­mot­ing high-qual­ity de­vel­op­ment.",
      "pubDate": "Mon, 27 Jan 2025 21:10:41 +0000",
      "isoDate": "2025-01-27T21:10:41.000Z",
      "author": "Alice Blair",
      "guid": "mZH23GpAAW8jS782a",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    },
    {
      "title": "Governance Course—Week 1 Reflections by Alice Blair",
      "link": "https://www.greaterwrong.com/posts/MmkFARsEEQaEEuayu/governance-course-week-1-reflections",
      "description": "[Epistemic sta­tus: I’m try­ing to make my think­ing leg­ible to my­self and oth­ers, rather than try­ing to com­pose some­thing highly pol­ished here. I think I have good rea­sons for say­ing what I say and will try to cite sources where pos­si­ble, but nonethe­less take it with some grains of salt. As with my last post, I am low­er­ing my stan­dards so that this post gets out at all.]\nI’m work­ing my way through Har­vard’s AI safety club (AISST)’s mod­ified ver­sion of the BlueDot Im­pact AI Gover­nance Cur­ricu­lum. I’m do­ing this be­cause I am pes­simistic about tech­ni­cal al­ign­ment on cur­rent AGI timelines, and so I am try­ing to ex­tend timelines by get­ting bet­ter at gov­er­nance.\nI’ve already taken MIT AI Align­ment (MAIA)’s ver­sion of the BlueDot Align­ment course (MAIA’s ver­sion is not pub­li­cly available), and I’ve taken MIT’s grad­u­ate-level deep learn­ing course, so I’ll mostly be skim­ming through the tech­ni­cal de­tails.\nThe pur­pose of this se­quence is for me to ex­plain what I learn, so that I in­ter­nal­ize it faster, and so that I can ac­tively dis­cuss with peo­ple about my takes on the read­ings. Read­ing this is not in­tended as a sub­sti­tute for ac­tu­ally do­ing any of the above-men­tioned courses, but it might give you some new ideas.\nEDIT: Th­ese posts were tak­ing up too much time, and were serv­ing as a blocker for me ac­tu­ally learn­ing the con­tent, so this post is dis­con­tinued. If you want my thoughts on any­thing spe­cific in the cur­ricu­lum, feel free to mes­sage me.\nI’m already fa­mil­iar with a lot of the con­tent by os­mo­sis and by my more tech­ni­cal AI safety back­ground, so this post will prob­a­bly be shorter than some of the later ones. Even though the cur­ricu­lum is or­ga­nized into weeks, I don’t plan on do­ing these posts weekly. I will do them as fast as I can, given my other com­mit­ments.\nBut what is a neu­ral net­work? (3Blue1Brown, 2017)\nI’ve watched this video a hand­ful of times in the past, and since then I’ve got­ten sig­nifi­cantly more tech­ni­cally skil­led at AI stuff. I’m gonna skip out on this one. If you haven’t seen it, it’s an ex­cel­lent ex­plainer.\nThe AI Triad and what it means for na­tional se­cu­rity strat­egy (Buchanan, 2020)\nTech­ni­cally the cur­ricu­lum only says to read the ex­ec­u­tive sum­mary. This is once again some ba­sic tech­ni­cal stuff that I mostly skimmed through. The triad it de­scribes is com­pute, data, and al­gorithms. Those are definitely im­por­tant things, now what about them? In the rest of the first sec­tion it goes on to define other stuff like “ma­chine learn­ing” and “su­per­vised learn­ing” and stuff like that.\nIn sec­tion 2, it talks about how the three el­e­ments of the triad can serve as lev­ers for poli­cy­mak­ers to con­trol AI de­vel­op­ment. In the con­text of the data, we see two main fo­cuses:\n\nDe­bi­as­ing datasets: mak­ing sure that datasets are not rep­re­sent­ing harm­ful bi­ases, and es­pe­cially mak­ing sure of this for high-stakes sys­tems like those mak­ing pa­role de­ci­sions. This mostly seems ir­rele­vant to cur­rent al­ign­ment and gov­er­nance work, not in that it’s ab­solutely unim­por­tant, but in that we have big­ger prob­lems to solve on our cur­rent tra­jec­tory.\n\nIn­for­ma­tion se­cu­rity: how do we se­cure ex­ist­ing large datasets that are quite valuable and po­ten­tially dan­ger­ous if mi­sused? How do gov­ern­ment datasets get se­cured, and who gets ac­cess to them. (since the gov­ern­ment has a lot of data, this is po­ten­tially valuable, they claim. This seems plau­si­bly right, but I don’t have strong in­tu­itions for how big the in­ter­net is rel­a­tive to how big gov­ern­ment records are. I’d guess that the in­ter­net is much big­ger, but the gov­ern­ment data has a higher den­sity of use­ful in­for­ma­tion.)\n\nIn the con­text of al­gorithms, they talk about tal­ent pipelines, visa con­trol, and worker re­train­ing, mostly from the con­text of do­ing ca­pa­bil­ities re­search. I don’t have strong pri­ors on this, but bring­ing in a lot of ex­tra tech­ni­cal skill seems like it will help ca­pa­bil­ities more than it will help safety, by de­fault. Still, weak over­all opinions here.\nIn the con­text of com­pute, they mostly talk about sup­ply chain reg­u­la­tions. This seems straight­for­wardly re­ally im­por­tant for reg­u­lat­ing scal­ing, al­though I feel like they’re prob­a­bly miss­ing some other parts of com­pute gov­er­nance.\nOver­all, even though this pa­per is mostly fo­cused on ca­pa­bil­ities re­search, it talks about some use­ful policy lev­ers. I think I already had a de­cent num­ber of these con­cepts in my head, but it’s good to make them more ex­plicit.\n4 charts that show why AI progress is un­likely to slow down (Hen­shall, 2023)\nThis ar­ti­cle shares some pretty stan­dard graphs and quotes, mostly from Epoch, as well as one from Con­tex­tu­aAI. While Epoch doesn’t di­rectly fore­cast AGI timelines here, I think these are still pretty im­por­tant for show­ing that things are just con­tin­u­ing up­wards. Seems sound and cor­rect.\nCan AI Scal­ing Con­tinue Through 2030?(Sevilla et al., 2024)\nThis gets into some re­ally good stuff about chip man­u­fac­tur­ing that I mostly didn’t know be­fore! They get re­ally into the weeds with TSMC and NVIDIA num­bers, which I won’t copy here. The tl;dr is that they fore­cast an in­crease in com­pute of the largest train­ing runs of about 4 OOMs by 2030, with some de­cent-sized un­cer­tainty given the large num­ber of con­straints play­ing to­gether. Figure 1 has a re­ally nice ex­plainer of their differ­ent es­ti­mates of im­por­tant con­straints (check it out on the web­site, since it’s in­ter­ac­tive and has mul­ti­ple slides).\nI think their main­line pre­dic­tion should re­ally ac­count more con­cretely for the un­prece­dented eco­nomic growth that AI is go­ing to bring over the next few years, and the un­prece­dented de­mand for AI chips that this cre­ates by de­fault as soon as this growth be­comes widely ap­par­ent. Their pre­dic­tions are be­ing very con­ser­va­tive in this re­spect, and mostly not ac­count­ing for AI speed­ing up eco­nomic growth as far as I can tell, nor are they ac­count­ing (in their main­line pre­dic­tion) for weird dis­con­ti­nu­ities in de­mand to TSMC as peo­ple re­al­ize just how big AI is be­com­ing.\nI don’t know how I made it this far with­out much un­der­stand­ing of the syn­thetic data gen­er­a­tion pro­cess, other than “just have the model make data.” I’m a bit dis­ap­pointed that this pa­per doesn’t in­clude syn­thetic data in their pre­dic­tion of dataset growth, but I un­der­stand that they don’t have ro­bust ground truths to base their pre­dic­tions off of, like in the other do­mains they in­ves­ti­gate. How­ever, this is an­other rea­son to sus­pect that they are un­der­es­ti­mat­ing the trends, since syn­thetic data will likely play an im­por­tant role. Since LLMs are much bet­ter at eval­u­at­ing the qual­ity of data than gen­er­at­ing high-qual­ity data, they can just gen­er­ate a bunch of raw syn­thetic data and filter it. They men­tion con­cerns of model col­lapse due to too much syn­thetic data, but once again don’t in­cor­po­rate this. I think that, in the age of o3 and other think­ing mod­els in­cen­tiviz­ing com­pa­nies to go hard on get­ting a lot of com­pute, it might be a lot eas­ier to get a lot of syn­thetic data us­ing their large clusters while they’re not ac­tively train­ing mod­els. It seems like the straight­for­ward way to turn an ex­cess of com­pute and a bot­tle­neck of data into a bal­ance of the two.\nHow­ever, the pa­per doesn’t pre­dict that we’ll end up in a low-data and high-com­pute sce­nario, given the other con­cerns about com­pute sup­ply chains, but it doesn’t rule that situ­a­tion out ei­ther. It pre­dicts that en­ergy and com­pute will be the pri­mary bot­tle­necks. I think that both of these are flex­ible given the eco­nomic up­set that I hy­poth­e­sized above. Their con­clu­sion: the 4x train­ing com­pute in­crease per year can likely con­tinue un­til at least 2030, and labs are in­cen­tivized to do so.\nEn­ergy bot­tle­necks seem the tight­est, and the most fea­si­ble scal­ing strat­egy is to build data cen­ters in a lot of differ­ent places so that they draw on differ­ent power grids. This is ap­par­ently worth the la­tency, which seems rea­son­able.\nConclusion\nI’ve heard a lot already about com­pute gov­er­nance, tal­ent pipelines and the like already. One thing that the last read­ing re­vealed as pos­si­bly im­por­tant is en­ergy gov­er­nance of AI. Maybe peo­ple are talk­ing about this and I’m just not hear­ing it, but if that’s the tight­est bot­tle­neck on de­vel­op­ment, then it’s a pow­er­ful lever in­deed. Th­ese sources feel a bit out­dated, since the land­scape has mas­sively shifted even in the time since these ar­ti­cles have come out (o1, then o3 and deepseek v3). I don’t think we know how much com­pute o3 took to train, but it’s giv­ing me the im­pres­sion that OpenAI pushed above the trend line in terms of all the differ­ent things we’re try­ing to pre­dict here, and so we have to ad­just fur­ther.\nI still feel like all this talk of “scal­ing to 2030” is a bit mis­guided, since I’m ready for AGI to be here sooner than that. It is, how­ever, fur­ther ev­i­dence that we’re prob­a­bly not go­ing to run out of re­sources be­fore AGI.",
      "pubDate": "Thu, 09 Jan 2025 04:48:27 +0000",
      "isoDate": "2025-01-09T04:48:27.000Z",
      "author": "Alice Blair",
      "guid": "MmkFARsEEQaEEuayu",
      "category": "LessWrong",
      "source": "LessWrong",
      "feedTitle": "Alice Blair's Posts - LessWrong 2.0 viewer"
    }
  ]
}
